# Investigaci√≥n: Tema 3 ‚Äì Notaci√≥n Asint√≥tica (Brassard & Bratley, 2006)
## 1. Introducci√≥n
La notaci√≥n asint√≥tica es una herramienta fundamental en el an√°lisis de algoritmos. Permite describir c√≥mo crece el tiempo de ejecuci√≥n (o el uso de memoria) de un algoritmo a medida que el tama√±o de entrada crece, sin necesidad de detallar aspectos de implementaci√≥n o hardware. Este concepto es esencial para comparar algoritmos de forma independiente a la plataforma en que se ejecuten.

Brassard y Bratley (2006) dedican el cap√≠tulo 3 de su obra a explicar con profundidad la notaci√≥n asint√≥tica, las clases de funciones m√°s comunes, y c√≥mo utilizarlas para analizar la eficiencia de los algoritmos.

## 2. Fundamentos de la Notaci√≥n Asint√≥tica
2.1. Objetivo
El objetivo principal de la notaci√≥n asint√≥tica es expresar el comportamiento de un algoritmo en el l√≠mite, es decir, c√≥mo se comporta cuando el tama√±o de entrada crece indefinidamente. Esto ayuda a abstraer los detalles espec√≠ficos y concentrarse en el "orden de magnitud" de la eficiencia.

2.2. Tama√±o de Entrada
Se asume que el tama√±o de entrada se representa mediante una variable, usualmente denotada como n. El an√°lisis se centra en c√≥mo una funci√≥n de tiempo o espacio T(n) crece respecto a n.

## 3. Tipos de Notaciones Asint√≥ticas
3.1. Notaci√≥n O Grande (Big-O): ùëÇ(ùëì(ùëõ))O(f(n))

La notaci√≥n O grande proporciona un l√≠mite superior para el crecimiento de un algoritmo. Es decir, asegura que, m√°s all√° de cierto punto, el algoritmo no ser√° m√°s lento que una funci√≥n dada (hasta una constante multiplicativa).
Definici√≥n formal:

Sea ùëá(ùëõ)T(n) una funci√≥n de tiempo de ejecuci√≥n. Se dice que:
ùëá(ùëõ)‚ààùëÇ(ùëì(ùëõ)) si¬†existen¬†constantes¬†ùëê>0y¬†ùëõ 0¬†tales¬†que¬†ùëá(ùëõ)‚â§ùëê‚ãÖùëì(ùëõ)  ¬†para¬†todo¬†ùëõ‚â•ùëõ0.T(n)‚ààO(f(n))¬†si¬†existen¬†constantes¬†c>0¬†y¬†n 0 tales¬†que¬†T(n)‚â§c‚ãÖf(n)¬†para¬†todo¬†n‚â•n 

3.2. Notaci√≥n Omega (Œ©): 

Esta notaci√≥n da un l√≠mite inferior al crecimiento de un algoritmo. Garantiza que el algoritmo no ser√° m√°s r√°pido que una funci√≥n dada (hasta constante multiplicativa).

Definici√≥n formal:

T(n) \in \Omega(f(n)) \text{ si existen constantes } c > 0 \text{ y } n_0 \text{ tales que } T(n) \geq c \cdot f(n) \text{ para todo } n \geq n_0.

3.3. Notaci√≥n Theta (Œò): 

La notaci√≥n Œò indica un ajuste exacto del orden de crecimiento, es decir, tanto l√≠mite superior como inferior. El algoritmo crece "a la misma velocidad" que  hasta constantes.

Definici√≥n formal:

T(n) \in \Theta(f(n)) \text{ si existen constantes } c_1, c_2 > 0 \text{ y } n_0 \text{ tales que } c_1 \cdot f(n) \leq T(n) \leq c_2 \cdot f(n) \text{ para todo } n \geq n_0.


---

4. Comparaci√≥n de Funciones de Crecimiento

Brassard y Bratley analizan el crecimiento de diferentes funciones, desde las m√°s lentas hasta las m√°s r√°pidas. Algunas funciones comunes en la pr√°ctica:

Orden de crecimiento	Ejemplo de algoritmo

	B√∫squeda binaria
	B√∫squeda lineal
	Mergesort, Heapsort
	Bubble sort, selecci√≥n, inserci√≥n
, 	Fuerza bruta en problemas NP



---

5. Importancia en el An√°lisis de Algoritmos

El uso de la notaci√≥n asint√≥tica permite:

Predecir el rendimiento de un algoritmo sin necesidad de implementarlo.

Comparar soluciones alternativas y elegir la m√°s eficiente.

Identificar cuellos de botella y √°reas cr√≠ticas de mejora.


Adem√°s, ayuda a desarrollar algoritmos escalables, especialmente importantes en problemas que manejan grandes vol√∫menes de datos.



6. Conclusi√≥n

La notaci√≥n asint√≥tica es una piedra angular en el estudio de algoritmos. Su dominio permite dise√±ar programas m√°s eficientes y sostenibles. Brassard y Bratley ofrecen una explicaci√≥n clara y rigurosa de estos conceptos, con ejemplos y fundamentos matem√°ticos, convirtiendo el cap√≠tulo 3 en una lectura esencial para cualquier estudiante de ciencias de la computaci√≥n